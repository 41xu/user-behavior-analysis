

<h1  align=center>《专业方向课程设计》大作业</h1>





<h3  align=center>题目：大规模用户行为分析系统</h3>







| 姓名 | 学号 | 班级 | 成绩 |
| ---- | ---- | ---- | ---- |
|      |      |      |      |
|      |      |      |      |
|      |      |      |      |
|      |      |      |      |
|      |      |      |      |

 





 



<h5  align=center>大连理工大学软件学院统</h5>

<h5  align=center>2019年7月</h5>

## 项目说明

神策题目：“神策分析” 是一个数据分析产品，包含一个完整的数据仓库。数据仓库的建设是数据进一步应用的基础。而一个完整的数据仓库通常有如下模块：数据采集（SDK、导入工具、LogAgent 等）、数据导入（清洗、入库）、存储、查询引擎、分析模型抽象层、接口层、UI 交互层。其中从 ”数据采集“ 到 ”导入存储“，涉及的技术细节非常繁杂，却又不能直观地回答初学者的疑问：“具体业务场景下，数据分析到底是如何应用的“ 这个问题。但查询层（包括模型抽象、查询引擎）则不同，查询一侧是贴近业务应用的一侧，相对而言会更加直观。所以本次的项目我们就以查询层为切入点，去尝试搭建一个大规模用户行为分析系统。

## 成员分工

| 成员   | 学号      | 分工                                                         |
| ------ | --------- | ------------------------------------------------------------ |
| 徐诗瑶 | 201692126 | 业务逻辑设计+Impala实现+模拟数据生成+总体设计+功能实现+优化方法实现 |
| 王贝   | 201672048 | 业务逻辑设计+界面设计+界面实现+环境搭建(Haoop+Hive+Impala)+数据导入+优化方法 |
| 吴任高 | 201671905 | 模拟数据生成+性能测试+正确性测试+编写用户使用手册            |

## 环境安装

### 1.Hadoop 

##### 环境准备

本机macOS Mojave 10.14.1 尝试在本地搭建伪分布式Hadoop

##### jdk下载

到官网下载了jdk8 jdk-8u191-macosx-x64.dmg安装jdk 之后配置环境变量如下：
```
JAVA_HOME="Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home"
export JAVA_HOME
CLASS_PATH="$JAVA_HOME/lib"
PATH=".$PATH:$JAVA_HOME/bin"
export PATH="$HOME/.yarn/bin:$PATH"
```

> 根据[这个教程](https://zhuanlan.zhihu.com/p/31162356)装好了java

##### ssh配置

先把系统偏好设置-共享-远程登录打开
```
ssh localhost
```
显示需要密码，实际上就是本机密码，这样不是很ok（具体到底哪里不ok我也不是很清楚

terminal中修改ssh设置
```
ssh-keygen -t rsa
[这里有啥输入的东西反正我们就按回车就完事]
cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
chmod og-wx ~/.ssh.authorized_keys
```
这时候我们再执行
```
ssh localhost
```
就会发现不需要密码ssh登陆了～就可以下载Hadoop了呢！

##### Hadoop下载安装

###### 官网下载

[官网提供的下载地址](https://www.apache.org/dyn/closer.cgi/hadoop/common/hadoop-2.8.5/hadoop-2.8.5.tar.gz)我下载了2.8.5

下载完之后我把这个tar.gz放到了/Documents/Hadoop 文件夹里 
```
cd Hadoop
tar -zxvf hadoop-2.8.5.tar.gz
```
（实际上就是我们在终端里解压的2333）

##### 添加Hadoop环境变量

在~/.bash_profile中添加
```
# Setting path for Hadoop
HADOOP_HOME="/Users/xusy/Documents/Hadoop/hadoop-2.8.5"
export HADOOP_HOME
export PATH=$PATH:HADOOP_HOME/sbin:$HADOOP_HOME/bin

export LD_LIBRARY_PATH=$HADOOP_HOME/lib/native/
export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native
export HADOOP_OPTS="-Djava.library.path=$HADOOP_HOME/lib/native:$HADOOP_COMMON_LIB_NATIVE_DIR"
```
具体路径根据hadoop的安装目录决定

下半部分的配置可以在上面提到的一些

接下来可以进入到我们的Hadoop目录里:

/hadoop-2.8.5/etc/hadoop/

然后修改core-site.xml, mapred-site.xml(这里是mapred-site.xml.template修改成.xml)

###### hadoop-env.sh

这个配置文件网上找到的大部分教程都要修改..但是..我看完我下载完之后打开的默认配置感觉不用改..于是没改..

---更新---

在这个配置文件中删掉了一些export前的注释, 关于JAVA_HOME, JSVC_HOME, HADOOP_HOME, HADOOP_HEAPSIZE=1000(或者2000), HADOOP_OPTS一些的注释都被去掉了，无需添加啥别的东西


---再来更新---

在又又又又启动的时候发现跑代码的时候会有些问题..报错信息显示的是Javahome的问题..以及Hadoophome的问题..因此还是对hadoop-env.sh文件作了修改，具体添加了javahome:
```
export JAVA_HOME="/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home"
export HADOOP_NAMENODE_OPTS="-Dhadoop.security.logger=${HADOOP_SECURITY_LOGGER:-INFO,RFAS} -Dhdfs.audit.logger=${HDFS_AUDIT_LOGGER:-INFO,NullAppender} $HADOOP_NAMENODE_OPTS"
export HADOOP_DATANODE_OPTS="-Dhadoop.security.logger=ERROR,RFAS $HADOOP_DATANODE_OPTS"

export HADOOP_SECONDARYNAMENODE_OPTS="-Dhadoop.security.logger=${HADOOP_SECURITY_LOGGER:-INFO,RFAS} -Dhdfs.audit.logger=${HDFS_AUDIT_LOGGER:-INFO,NullAppender} $HADOOP_SECONDARYNAMENODE_OPTS"

export HADOOP_NFS3_OPTS="$HADOOP_NFS3_OPTS"
export HADOOP_PORTMAP_OPTS="-Xmx512m $HADOOP_PORTMAP_OPTS"
```
具体的配置文件放到了我的 GitHub -> HadoopClassNote里～


**同样的：**在hadoop-env.sh, mapred-env.sh, yarn-env.sh这三个文件里都要对JAVA_HOME进行添加修改

###### core-site.xml

```
<configuration>
	<property>
		<name>fs.default.name</name>
		<value>hdfs://localhost:9000</value>
	</property>
	<property>
		<name>hadoop.tmp.dir</name>
		<value>/Users/xusy/Documents/Hadoop</value>  👈🏿是自定义的放hdfs文件的目录这里我就直接放在了我的Hadoop目录里
	</property>
</configuration>
```

(后来由于namenode的相关信息存在了系统的tmp文件夹里，导致每次系统重启的时候都会出现配置不能成功启动，我们每次都要格式化namenode，这样就非常不ok，所以我们对这个文件稍微修改了一下)

```
	<property>
		<name>hadoop.tmp.dir</name>
		<value>/Users/xusy/hadoop_tmp</value> 
	</property>
```

###### mapred-site.xml

这个文件实际上我下载完的后缀是.xml.template(还是啥玩意反正是后面有个后缀，被我直接修改成了.xml)
```
<configuration>
  <property>
    <name>mapred.job.tracker</name>
    <value>localhost:9010</value>
  </property>
  <property>
    <name>mapreduce.framework.name</name>
    <value>yarn</value>
  </property>
</configuration>
```

###### hdfs-site.xml

```
<configuration>
	<!--伪分布式-->
	<property>
		<name>dfs.replication</name>
		<value>1</value>
	</property>
</configuration>
```
这里的变量dfs.replication指定了每个HDFS数据库的复制次数，通常为3，而我们要在本机建立一个伪分布式的DataNode所以这个值改成了1

为了保存hdfs的元数据和data相关文件，这里后来添加了property：
```
<configuration>
	<!--伪分布式-->
  <property>
    <name>dfs.namenode.name.dir</name>
    <value>/Users/xusy/Documents/Hadoop/dfs/name</value>
  </property>
  <property>
    <name>dfs.datanode.data.dir</name>
    <value>/Users/xusy/Documents/Hadoop/dfs/data</value>
  </property>
	<property>
		<name>dfs.replication</name>
		<value>1</value>
	</property>
  <property>
    <name>dfs.permissions</name>
    <value>false</value>
  </property>
</configuration>

```
###### yarn-site.xml

```
<configuration>
	<property>
		<name>yarn.nodemanager.aux-services</name>
		<value>mapreduce_shuffle</value>
	</property>

<!-- Site specific YARN configuration properties -->

<!-- 集群配置-->
  <!--      <property>
      <name>yarn.resourcemanager.hostname</name>
      <value>master</value>
      </property> -->

</configuration>
```
同样的稍微做了修改
```
<configuration>
	<property>
		<name>yarn.nodemanager.aux-services</name>
		<value>mapreduce_shuffle</value>
	</property>
  <property>
    <name>yarn.resourcemanager.resource-tracker.address</name>
    <value>localhost:8031</value>
  </property>
    <property>
    <name>yarn.resourcemanager.address</name>
    <value>localhost:8032</value>
  </property>
    <property>
    <name>yarn.resourcemanager.admin.address</name>
    <value>localhost:8033</value>
  </property>
    <property>
    <name>yarn.resourcemanager.scheduler.address</name>
    <value>localhost:8034</value>
  </property>
    <property>
    <name>yarn.resourcemanager.webapp.address</name>
    <value>localhost:8088</value>
  </property>
    <property>
    <name>yarn.log-aggregation-enable</name>
    <value>true</value>
  </property>
    <property>
    <name>yarn.log.server.url</name>
    <value>http://localhost:19888/jobhistory/logs/</value>
  </property>
<!-- Site specific YARN configuration properties -->

<!-- 集群配置-->
  <!--      <property>
      <name>yarn.resourcemanager.hostname</name>
      <value>master</value>
      </property> -->
</configuration>
```

###### log4j.properties

在具体跑代码的时候会有些WARNING(但实际上你的代码并没有什么问题..)因此我们要在log4j.properties文件后追加一行内容：
```
log4j.logger.org.apache.hadoop.util.NativeCodeLoader=ERROR
```

##### 启动Hadoop

> 每次操作的时候都要进入这个Hadoop文件夹哦（当然我觉得如果把这个添加到环境变量里会不会好点..我也不知道我瞎说的

终端进入到Hadoop的文件夹下
我这里的文件夹就是
```
/Users/xusy/Documents/Hadoop/hadoop-2.8.5
```
执行
```
./bin/hdfs namenode -format
```
格式化文件系统（对namenode进行初始化)（好像是只要初始化一次就好了就是最开始建系统的时候..之后如果每次启动你都初始化..那么是会有问题的！）

---
更新

---

在启动Hadoop，jps之后可能会出现你的namenode没起来的这个问题，这个时候就得格式化一下namenode，具体的话👇🏿

这里的namenode format的问题：由于namenode的信息是存在了系统的tmp文件夹下的，如果你到这里看的话是能看见这些的：

![tmp](/img/tmp.png)

每次启动的话tmp是会清空的，我也不知道咋回事反正，虽然我在core-site.xml文件里明明定义的是tmp存在了Hadoop文件夹下...但还是有这个问题..所以就重新在我的xusy用户下面新建了一个hadoop_tmp文件夹，把上面core-site.xml里存temp的那个文件夹路径改成了
```
	<property>
		<name>hadoop.tmp.dir</name>
		<value>/Users/xusy/hadoop_tmp</value> 
```
然后重新format就可以了..不知道再重新启动我的电脑的时候还会不会有这个问题..如果有那就再更新一下..		


接下来启动namenode & datanode （感觉就是启动dfs文件系统)
```
./sbin/start-dfs.sh
```
中间会有一个询问yes/no的我们输入yes就好了..
启动yarn
```
./sbin/start-yarn.sh
```
启动日志管理log的histroyserver 
```
./mr-jobhistory-daemon.sh start historyserver
```
👆🏿输入了这个命令就可以在jps里看见JobHistoryServer了

当然以上的命令都是在hadoop-2.8.5下面运行的

想要关闭的话..
```
./sbin/stop-all.sh
# stop-dfs.sh stop-yarn.sh
```

查看当前的hadoop运行情况:
```
xushiyaodeMacBook-Pro:sbin xusy$ jps
39696 SecondaryNameNode
39809 ResourceManager
49810 JobHistoryServer
39891 NodeManager
39507 NameNode
69306 
39595 DataNode
73471 Jps
```
测试一下我们能不能进入到overview界面呢！

NameNode - http://localhost:50070

ps:这里有一个Hadoop2和Hadoop3对应端口修改的表在下面：

NameNode端口

| Hadoop2 | Hadoop3 |
| ------: | ------: |
|   50470 |    9871 |
|   50070 |    9870 |
|    8020 |    9820 |

Secondary NN端口

| Hadoop2 | Hadoop3 |
| ------: | ------: |
|   50091 |    9869 |
|   50090 |    9868 |

DataNode端口

| Hadoop2 | Hadoop3 |
| ------: | ------: |
|   50020 |    9867 |
|   50010 |    9866 |
|   50475 |    9865 |
|   50075 |    9864 |

##### 继续启动！！！

由于我们刚刚到配置..这里的namenode1对应的就是我们本机localhost啦～(所以下面的web查看正常输入的URL应该是namenode1+端口的)

overview查看！

查看HDFS：

http://localhost:50070

查看YARN：

http://localhost:8088

查看MR启动JobHistory Server(这里暂时出了问题..让我研究一下..)

http://localhost:19888

### 2. Hive

一、安装 **MySQL**

1. 上传MySQL在线安装源的配置文件

用WinSCP（root账号连接）CentOS服务器

将mysql-community.repo 文件上传到 /etc/yum.repos.d/ 目录

将RPM-GPG-KEY-mysql 文件上传到 /etc/pki/rpm-gpg/ 目录

 

2. 更新yum源并安装mysql server（默认同时会安装mysql client）

> yum repolist

> yum install mysql-server

 

3. 查看MySQL各组件是否成功安装

> rpm -qa | grep mysql

![img](http://ww1.sinaimg.cn/large/006tNc79ly1g4lo4au6h4j308j01ngm8.jpg) 

 

 

二、配置**MySQL**

1. 启动MySQL Server并查看其状态

> systemctl start mysqld

> systemctl status mysqld

![img](http://ww4.sinaimg.cn/large/006tNc79ly1g4lo815xcsj30dz028gmn.jpg)、

2. 查看MySQL版本

> mysql -V

![img](http://ww2.sinaimg.cn/large/006tNc79ly1g4lo83tyhbj30dz00mweq.jpg) 

 

3. 连接MySQL，默认root密码为空

> mysql -u root   (这个命令不好用，用 mysql -u root -p )

> mysql> s

这里如果使用 > myswl -u root 会报以下错误

> ERROR 1044 (42000): Access denied for user ''@'localhost' to database 'mysql' 

4. 查看数据库

> mysql> show databases; （注意：必须以分号结尾，否则会出现续行输入符“>”）

 

5. 创建hive元数据数据库（metastore）

> mysql> create database hive; 

![img](http://ww4.sinaimg.cn/large/006tNc79ly1g4lo9qcxrpj308o04z0tu.jpg) 

 

6. 创建用户hive，密码是123456

> mysql> CREATE USER 'hive'@'%' IDENTIFIED BY '123456';

注意：删除用户是DROP USER命令 

 

7. 授权用户hadoop拥有数据库hive的所有权限

mysql> GRANT ALL PRIVILEGES ON hive.* TO 'hive'@'%' WITH GRANT OPTION;

 

8. 查看新建的MySQL用户（数据库名：mysql，表名：user）

> mysql> select host,user,password from mysql.user;

![img](http://ww1.sinaimg.cn/large/006tNc79ly1g4lo9tbz18j30dz04imyu.jpg) 

 

9. 删除空用户记录，如果没做这一步，新建的hive用户将无法登录，后续无法启动hive客户端

> mysql> delete from mysql.user where user='';

 

10. 刷新系统授权表（不用重启mysql服务）

> mysql> flush privileges; 

 

11. 测试hive用户登录

> mysql -u hive -p

> Enter password：123456



**三、安装和配置hive**

1. 下载hive

> Wget https://mirrors.tuna.tsinghua.edu.cn/apache/hive/hive-2.3.5/apache-hive-2.3.5-bin.tar.gz

2. 解压hive-1.1.0-cdh5.12.1.tar.gz到/home/hadoop

> $ tar zxvf apache-hive-2.3.5-bin.tar.gz

 

3. 在.bash_profile文件中添加hive环境变量

> export HIVE_HOME=/home/hadoop/hive-1.1.0-cdh5.12.1

> export PATH=$HIVE_HOME/bin:$PATH

4. 使上述设置生效

   > $ source .bash_profile

 

5. 编辑$HIVE_HOME/conf/hive-env.sh文件，在末尾添加HADOOP_HOME变量

> cd $HIVE_HOME/conf

> cp hive-env.sh.template hive-env.sh	（默认不存在，可从模板文件复制）

> vi hive-env.sh

> HADOOP_HOME=/root/Hadoop/hadoop-2.8.5

 

6. 新建$HIVE_HOME/conf/hive-site.xml文件

```xml
<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
        <property>
                <name>javax.jdo.option.ConnectionDriverName</name>
                <value>com.mysql.jdbc.Driver</value>
        </property>
        <property>
                <name>javax.jdo.option.ConnectionURL</name>
                <value>jdbc:mysql://localhost:3306/hive</value>
        </property>
        <property>
                <name>javax.jdo.option.ConnectionUserName</name>
                <value>hive</value>
        </property>
        <property>
                <name>javax.jdo.option.ConnectionPassword</name>
                <value>123456</value>
        </property>

		<property>
				<name>hive.metastore.warehouse.dir</name>
				<value>/hive/warehouse</value>
		</property>
		<property>
				<name>hive.exec.scratchdir</name>
				<value>/hive/tmp </value>
		</property>
        <property>
                <name>hive.metastore.schema.verification</name>
                <value>false</value>
        </property>
</configuration>
```



 

7. 在HDFS上创建数据仓库目录（用于存放hive数据文件）和临时目录

> hdfs dfs -mkdir -p /hive/warehouse /hive/tmp

 

8. 下载mysql连接驱动，下载地址：https://dev.mysql.com/downloads/connector/j/

![img](file:////var/folders/nm/nfxnvn057nq5rsjjdhz11rsw0000gn/T/com.kingsoft.wpsoffice.mac/wps-bellick/ksohtml/wpsJYMEDH.png) 

	下载文件(.tar.gz)解压后，将其中的mysql-connector-java-8.0.13.jar文件上传到 $HIVE_HOME/lib目录下

 


9. 启动hive

> hive

10. 查看hive数据库 （注意：命令以分号结尾）

> hive> show databases;

![img](file:////var/folders/nm/nfxnvn057nq5rsjjdhz11rsw0000gn/T/com.kingsoft.wpsoffice.mac/wps-bellick/ksohtml/wpsY2lKug.jpg) 

default是默认数据库

11. 退出hive

> hive> quit;

##### Hive> Show databases; 报错

> hive> show databases;
> FAILED: SemanticException org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: MetaException(message:Hive metastore database is not initialized. Please use schematool (e.g. ./schematool -initSchema -dbType ...) to create the schema. If needed, don't forget to include the option to auto-create the underlying database in your JDBC connection string (e.g. ?createDatabaseIfNotExist=true for mysql))



在HIVE_HOME/conf/hive-site.xml 中添加如下配置

```
<property>
<name>datanucleus.schema.autoCreateAll</name>
<value>true</value>
</property>
```

### 3. Impala 

1. 先去http://archive.cloudera.com/beta/impala-kudu/redhat/7/x86_64/impala-kudu/0/RPMS/x86_64/下载所需的包
2. 依次安装这些包

```shell
rpm -ivh bigtop-utils-xxx.rpm
rpm -ivh impala-xxx.rpm
rpm -ivh impala-xxx.rpm
rpm -ivh impala-xxx.rpm
rpm -ivh impala-xxx.rpm
rpm -ivh impala-xxx.rpm
rpm -ivh impala-xxx.rpm
rpm -ivh impala-xxx.rpm
```

3. impala 配置

   3.1 添加hadoop安装目录下的core-site.xml,hdfs.xml 和 hive的hive-site.xml 到/etc/impala/conf 

   3.2 修改文件 /etc/default/bigtop-utils ，新增java_home路径；

   3.3 修改文件 /etc/default/impala，只需修改前两行，改为主节点的ip地址或者hostname, 若/etc/hosts文件配置了 127.0.0.1 localhost ，也可不做修改

   3.4 修改core-site.xml，新增以下几项:

   ```
   <property>
           <name>dfs.client.read.shortcircuit</name>
           <value>true</value>
   </property>
   <property>
           <name>dfs.client.read.shortcircuit.skip.checksum</name>
           <value>false</value>
   </property>
   <property>
           <name>dfs.datanode.hdfs-blocks-metadata.enabled</name>
           <value>true</value>
   </property>
   ```

   3.5 修改hdfs-site.xml，新增以下几项:

   ```xml
   <property>
           <name>dfs.datanode.hdfs-blocks-metadata.enabled</name>
           <value>true</value>
   </property>
   <property>
           <name>dfs.block.local-path-access.user</name>
           <value>impala</value>
   </property>
   <property>
           <name>dfs.client.file-block-storage-locations.timeout.millis</name>
           <value>60000</value>
   </property>
   ```

   3.6 权限配置

   > 1. sermod -G hdfs,hadoop impala
   > 2. groups impala

   3.7 创建impala在hdfs目录，赋予权限(单节点即可)：

   > 1.  hdfs dfs -mkdir /user/impala
   > 2.  hadoop fs -chown impala /user/impala*

4. 启动impala 之前，先启动hadoop ,hiveserver2的服务(若配置了，否则启动hiveserver服务)

5. 启动impala服务,  主机节点即可，从机可以不启动impala-server服务,所示的ip为刚才配置文件所配的ip或者为ip对应的 hostname，未修改则为127.0.0.1：

   ```shell
   [root@master run]# service impala-state-store restart --kudu_master_hosts=192.168.174.132:7051
   Stopped Impala State Store Server:                         [  确定  ]
   Started Impala State Store Server (statestored):           [  确定  ]
   [root@master run]# service impala-catalog restart --kudu_master_hosts=192.168.174.132:7051
   Stopped Impala Catalog Server:                             [  确定  ]
   Started Impala Catalog Server (catalogd) :                 [  确定  ]
   [root@master run]# service impala-server restart --kudu_master_hosts=192.168.174.132:7051
   Stopped Impala Server:                                     [  确定  ]
   Started Impala Server (impalad):                           [  确定  ]
   [root@master run]# 
   ```

6. 启动 impala-shell

> 基于 https://blog.csdn.net/qq_41792743/article/details/87979146

## 需求分析



## 数据导入

将数据文件拷贝到HDFS上，然后建立一张impala外部表，将外部表的存储位置，指向数据文件

1. 用scp将数据文件传到服务器

2. 在HDFS上建立存储数据的目录

   > su hdfs
   >
   > hdfs dfs -mkdir -p  /user/impala/data /user/impala/data/event_export /user/impala/data/user_export

3. 修改HDFS目录权限（如果需要）

   > hdfs dfs -chmod 777 /user/impala/data/event_export 

4. 将数据文件传到HDFS指定目录上

   > hdfs dfs -put /home/work/event_export/xxxxxx.xxx  /user/impala/data/event_export 

   >  hdfs dfs -put /home/work/user_export/xxxxxx.xxx  /user/impala/data/user_export 

5. 在impala-shell中建立外部表，并指向数据文件

   > Impala-shell > CREATE TABLE rawdata.event_export (
   >   event_id INT,
   >   month_id INT,
   >   week_id INT,
   >   user_id BIGINT,
   >   distinct_id STRING,
   >   time TIMESTAMP,
   >   day INT,
   >   event_bucket INT,
   >   _offset BIGINT,
   >   p__app_version STRING,
   >   ...
   > )
   > STORED AS TEXTFILE
   > LOCATION '/user/impala/data/event_export '

## 总体设计



## 界面设计

按照神策的文档，我们实现了一个阉割版的界面

* 对于事件分析，我们允许用户选择
  * 事件的时间区间
  * 分析指标
  * 分组展示方式

![](http://ww1.sinaimg.cn/large/006tNc79ly1g50gaf712xj30vq0a0mye.jpg)

* 对于留存分析，用户可以选择
  * 事件起止日期
  * 用户初始行为
  * 用户后续行为

![](http://ww1.sinaimg.cn/large/006tNc79ly1g50gaqm0v0j30vq08i75d.jpg)

* 对于漏斗分析，用户可以选择
  * 年份
  * 月份
  * 构成漏斗的行为 X 4

![](http://ww2.sinaimg.cn/large/006tNc79ly1g50g9yya1gj30vq0fxdgv.jpg)

## 功能实现



## 优化方法

1. 存储方式

   将TEXT数据转换成Parquet存储

2. 分区

   将数据按照 (day, event_bucket )分区

> create table rawdata.parquet_partiton(
>
> xxx
>
>  ) 
>
> select ( xxxx ,day, event_bucket) from xxx
>
>  stored as parquet 
>
> partitoned by(day,event_bucket)

## 模拟数据生成

## 正确性测试

## 性能测试